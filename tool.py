import json
import requests
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.tools import tool
from services import get_route, get_lockers

# # --- ë²¡í„° DB ë° ë¦¬íŠ¸ë¦¬ë²„ ì„¤ì • ---
# embedding_model = OpenAIEmbeddings(model="text-embedding-3-small")
# vectorstore = Chroma(embedding_function=embedding_model, persist_directory="./tour_db")
# retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

# --- 1. ë²¡í„° DB ë° ë¦¬íŠ¸ë¦¬ë²„ ì„¤ì • ---
embedding_model = OpenAIEmbeddings(model="text-embedding-3-small")
vectorstore = Chroma(embedding_function=embedding_model, persist_directory="./tour_db")

# --- 2. [ì‹ ê·œ] RAG ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜ ---
def process_rag_docs(docs):
    """RAG ë°ì´í„°ì˜ lon í•„ë“œë¥¼ lngë¡œ ë³€í™˜í•˜ê³  ìœ ë‹ˆì½”ë“œë¥¼ ì •ì œí•©ë‹ˆë‹¤."""
    cleaned = []
    for d in docs:
        content = d.page_content
        try:
            if "\\u" in content:
                content = content.encode('utf-8').decode('unicode_escape')
        except: pass

        metadata = d.metadata.copy()
        # ë°ì´í„°ì˜ 'lon'ì„ í”„ë¡ íŠ¸ì—”ë“œì™€ ê¸¸ì°¾ê¸° API ê·œê²©ì¸ 'lng'ë¡œ ë§¤í•‘
        if 'lon' in metadata:
            metadata['lng'] = metadata.pop('lon')
            
        cleaned.append({"content": content[:500], "metadata": metadata})
    return json.dumps(cleaned, ensure_ascii=False)

# --- 3. [ì‹ ê·œ] ì¹´í…Œê³ ë¦¬ë³„ ì„¸ë¶„í™” ë„êµ¬ ---

@tool
def attraction_search_tool(query: str):
    """ì„œìš¸ì˜ ë°•ë¬¼ê´€, ë¯¸ìˆ ê´€, í…Œë§ˆ ê±°ë¦¬, ê´€ê´‘ ëª…ì†Œ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    # museum_artì™€ tourism_street ì¹´í…Œê³ ë¦¬ í•„í„°ë§
    retriever = vectorstore.as_retriever(search_kwargs={
        "k": 5, 
        "filter": {"category": {"$in": ["museum_art", "tourism_street"]}}
    })
    return process_rag_docs(retriever.invoke(query))

@tool
def market_search_tool(query: str):
    """ì„œìš¸ì˜ ì „í†µì‹œì¥, ë§›ì§‘ ê³¨ëª© ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    # traditional_market ì¹´í…Œê³ ë¦¬ í•„í„°ë§
    retriever = vectorstore.as_retriever(search_kwargs={"k": 5, "filter": {"category": "traditional_market"}})
    return process_rag_docs(retriever.invoke(query))

@tool
def station_search_tool(query: str):
    """ì„œìš¸ ë° ìˆ˜ë„ê¶Œ ì§€í•˜ì² ì—­ì˜ ìœ„ì¹˜ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    # subway_station ì¹´í…Œê³ ë¦¬ í•„í„°ë§
    retriever = vectorstore.as_retriever(search_kwargs={"k": 3, "filter": {"category": "subway_station"}})
    return process_rag_docs(retriever.invoke(query))

# @tool
# def convenience_search_tool(query: str):
#     """í™”ì¥ì‹¤, ê´€ê´‘ì•ˆë‚´ì†Œ ë“± ì—¬í–‰ í¸ì˜ì‹œì„¤ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
#     # public_toiletê³¼ tourist_info_center ì¹´í…Œê³ ë¦¬ í•„í„°ë§
#     retriever = vectorstore.as_retriever(search_kwargs={
#         "k": 5, 
#         "filter": {"category": {"$in": ["public_toilet", "tourist_info_center"]}}
#     })
#     return process_rag_docs(retriever.invoke(query))

@tool
def vector_search_tool(query: str):
    """ì„œìš¸ ê´€ê´‘ì§€ ì •ë³´, ë§›ì§‘, ì´ìš© ì‹œê°„ ë° API ëª…ì„¸ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    retriever = vectorstore.as_retriever(search_kwargs={
        "k": 5, "filter": {"category": {"$in": ["museum_art", "tourism_street","traditional_market"]}}})
    docs = retriever.invoke(query)
    
    # ë””ë²„ê¹…ìš© ë¡œê·¸: ìœ ë‹ˆì½”ë“œ ê¹¨ì§ ë°©ì§€ë¥¼ ìœ„í•´ ì§ì ‘ í•œê¸€ë¡œ ì¶œë ¥ ì‹œë„
    print(f"\nğŸ” [RAG ê²€ìƒ‰ ì¿¼ë¦¬]: {query}")
    
    cleaned_results = []
    for i, d in enumerate(docs):
        # 1. ìœ ë‹ˆì½”ë“œ ì´ìŠ¤ì¼€ì´í”„ ë¬¸ìì—´(\uc788...)ì´ ë“¤ì–´ìˆì„ ê²½ìš° ì‹¤ì œ í•œê¸€ë¡œ ë³€í™˜
        content = d.page_content
        try:
            # ë¦¬í„°ëŸ´ ë¬¸ìì—´ë¡œ ì €ì¥ëœ ê²½ìš° ë””ì½”ë”© ì‹œë„
            if "\\u" in content:
                content = content.encode('utf-8').decode('unicode_escape')
        except Exception:
            pass # ë³€í™˜ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ìœ ì§€

        # 2. ë„ˆë¬´ ê¸´ ë‚´ìš©ì€ í† í° ì ˆì•½ì„ ìœ„í•´ ì˜ë¼ë‚´ê¸°
        # ê²€ìƒ‰ ê²°ê³¼ 1ê°œë‹¹ ì•½ 500ì ì •ë„ë¡œ ì œí•œí•˜ëŠ” ê²ƒì´ íš¨ìœ¨ì ì…ë‹ˆë‹¤.
        summarized_content = content[:500] 
        
        print(f"   - ê²€ìƒ‰ ê²°ê³¼ {i+1} (ì •ì œë¨): {summarized_content[:30]}...")
        
        cleaned_results.append({
            "content": summarized_content,
            "metadata": d.metadata
        })
    
    # ensure_ascii=Falseë¡œ ì„¤ì •í•˜ì—¬ LLMì—ê²Œ í•œê¸€ ì›ë¬¸ì„ ê·¸ëŒ€ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.
    return json.dumps(cleaned_results, ensure_ascii=False)
#tool.py ë‚´ route_tool ì˜ˆì‹œ
# @tool
# def route_tool(start: str, end: str):
#     """
#     ë‘ ì§€ì  ì‚¬ì´ì˜ ê²½ë¡œë¥¼ ê²€ìƒ‰í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.
#     ì…ë ¥ê°’: start(ìœ„ë„,ê²½ë„), end(ìœ„ë„,ê²½ë„)
#     """
#     try:
#         # 1. API í˜¸ì¶œ (íƒ€ì„ì•„ì›ƒ ì„¤ì • ê¶Œì¥)
#         response = requests.get(
#             f"http://localhost:5000/api/route?start={start}&end={end}",
#             timeout=10
#         )
        
#         # 2. HTTP ìƒíƒœ ì½”ë“œ í™•ì¸ (404, 500 ë“± ë°©ì§€)
#         response.raise_for_status()

#         # 3. ë¹ˆ ì‘ë‹µ(Empty Body) ì²´í¬ - ì§ˆë¬¸í•˜ì‹  ì—ëŸ¬ì˜ í•µì‹¬ ì›ì¸ í•´ê²°
#         if not response.text.strip():
#             return "ì‹œìŠ¤í…œ ì•Œë¦¼: ê²½ë¡œ ê²€ìƒ‰ ê²°ê³¼ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ì¢Œí‘œê°€ ìœ íš¨í•œì§€ í™•ì¸í•˜ì„¸ìš”."

#         # 4. JSON íŒŒì‹± ì‹œë„
#         try:
#             data = response.json()
#             # í•œê¸€ì´ ê¹¨ì§€ì§€ ì•Šë„ë¡ ì§ë ¬í™”í•˜ì—¬ ë°˜í™˜
#             return json.dumps(data, ensure_ascii=False)
#         except json.JSONDecodeError:
#             # JSONì´ ì•„ë‹Œ HTML ì—ëŸ¬ í˜ì´ì§€ ë“±ì´ ì™”ì„ ë•Œ ì²˜ë¦¬
#             return f"ì‹œìŠ¤í…œ ì•Œë¦¼: ì„œë²„ ì‘ë‹µ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. (ì‘ë‹µ ë‚´ìš©: {response.text[:100]})"

#     except requests.exceptions.RequestException as e:
#         # ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¬¸ì œë‚˜ ì„œë²„ê°€ êº¼ì ¸ ìˆì„ ë•Œ
#         return f"ì‹œìŠ¤í…œ ì•Œë¦¼: API ì„œë²„ ì—°ê²° ì‹¤íŒ¨. ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”. (ì—ëŸ¬: {str(e)})"
#     except Exception as e:
#         # ê¸°íƒ€ ì˜ˆìƒì¹˜ ëª»í•œ ëª¨ë“  ì—ëŸ¬ ì²˜ë¦¬
#         return f"ì‹œìŠ¤í…œ ì•Œë¦¼: ì˜ˆê¸°ì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ({str(e)})"
    
# @tool
# def lockers_tool(_query: str = ""):
#     """ì„œìš¸ ì£¼ìš” ì§€í•˜ì² ì—­ ë° ê´€ê´‘ì§€ì˜ ë¬¼í’ˆ ë³´ê´€ì†Œ ìœ„ì¹˜ì™€ í˜„í™©ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
#     return json.dumps(get_lockers(), ensure_ascii=False)





# ë‹¤ë¥¸ íŒŒì¼ì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸° ì‰½ê²Œ ë¦¬ìŠ¤íŠ¸ë¡œ ë¬¶ì–´ì¤ë‹ˆë‹¤.
tools = [
    attraction_search_tool, 
    market_search_tool, 
    station_search_tool,
    vector_search_tool, 
    # convenience_search_tool, 
    #route_tool, lockers_tool]
]
